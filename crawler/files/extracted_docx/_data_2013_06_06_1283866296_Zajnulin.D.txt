Правительство Российской Федерации



Федеральное государственное автономное образовательное 

учреждение высшего профессионального образования 

«Национальный исследовательский университет 

"Высшая школа экономики"»



Санкт-Петербургский филиал федерального  государственного 

автономного  образовательного учреждения высшего профессионального образования 

«Национальный  исследовательский  университет "Высшая школа экономики"»



Факультет ____экономики_________



Кафедра ____экономической теории_______





БАКАЛАВРСКАЯ РАБОТА 

На тему: «Разработка динамического фильтра отсеивания ошибок в методе стохастической аппроксимации»



Направление/специальность ________экономика___________

 



Студент группы № 143 

Зайнулин Денис Айратович

Научный руководитель:

доцент, каф. эк-ой теории

 Светуньков Иван Сергеевич





Санкт-Петербург

 2013



























Введение



В современном, динамично развивающемся мире использование различных моделей для предсказания будущего стало обычным делом. Существует огромное количество моделей, которые используются в той или иной ситуации, в зависимости от ряда данных или ожидаемого результата. Однако ни одна из существующих моделей не является совершенной, у каждой есть свои недостатки и достоинства и каждая из них является лишь приближённым отражением реальности. 

Практически одновременно с появлением первых описательных моделей, весьма остро встал вопрос о способности модели точно описывать ряд данных, или аппроксимировать его. Ведь фактически каждый ряд эволюционирует и модель должна двигаться вместе с этой эволюцией, а не стоять на месте. В связи с этим был разработан метод стохастической аппроксимации, который позволял адаптировать коэффициенты первоначальной модели в зависимости от изменений, которые происходили в ряде данных. 

От точности прогноза зависят прибыли компаний, успешность выполнения бизнес планов, государственное регулирование социально-экономической жизни населения, в связи с чем, в современном мире вопрос аппроксимирования стал ещё острее, ведь точность прогноза идёт уже не на целые числа, а на десятые и не редко на сотые доли. Метод стохастической аппроксимации, упомянутый выше, хоть и показывает весьма хорошие результаты при адаптации коэффициентов модели и уже зарекомендовал себя, однако некоторые его части при реализации на практике слабо формализованы. 

Исходя из всего вышесказанного, считаю, что тема моей выпускной квалификационной работы является актуальной, так как основной её целью является модернизация метода стохастической аппроксимации. Для достижения поставленной в ВКР цели мне необходимо будет решить ряд следующих задач:

Изучить зарубежную и отечественную литературу по МСА

Применить на практике МСА и выявить возможные недостатки

Исходя из полученных во время обучения знаний, попытаться устранить возможные недостатки, а также формализовать слабоунифицированные части МСА

Применить на практике на достаточном количестве временных рядов модернизированный метод стохастической аппроксимации и сравнить полученные результаты с применением обычного МСА

Сделать выводы о корректности и возможности применения модернизации на практике.

Объектом исследования моей выпускной квалификационной работы являются временные ряды, а предметом - это модели, описывающие их, и способы адаптации моделей к эволюционным процессам во временных рядах.

При написании ВКР я использую следующие методы исследования:

Изучение литературы соответствующей тематике ВКР литературы.

Индуктивные методы – перебор возможных способов модернизации МСА и выбор наиболее эффективного из них.

Наблюдение за изменениями в МСА после различных дополнений, отброс ненужных или неэффективных.

Математические и статистические методы при применении как самого МСА на практике, так и его модернизированной формы.





Глава 1. Метод стохастической аппроксимации (МСА)

 1.1. Основные алгоритмы МСА



Основные алгоритмы стохастической аппроксимации были разработаны в начале 1950-х годов Робинсоном, Монро, Кифером и Вольфовицем, которые, впоследствии, получили названия в честь своих разработчиков. Также алгоритмы стохастической аппроксимации, в дальнейшем МСА, стали предметом множества теоретических и практических работ. Основной парадигмой МСА является следующее стохастическое разностное уравнение:

 

 				(1.1)



где величина  это какое-нибудь значение из Евклидового пространства. Произвольное линейное пространство называется Евклидовым, если: 1) известно правило, посредством которого любым двум элементам этого множества ставится в соответствие число, называемое скалярным произведением этих элементов; 2) указанное правило таково, что для скалярного произведения справедливы следующие свойства: переместительное, сочетательное относительно числового множителя, распределительное относительно суммы и произведение элемента на себя больше нуля, если он является ненулевым вектором и равно нулю, если является нулевым вектором.  случайная величина, а   - «размер шага», который является бесконечно малой величиной, стремящейся к нулю при увеличении количества итераций - n, то есть . В простейшем случае θ – параметр системы, а Y – функция наблюдений, подверженных шуму и используемых в системе, когда параметр принимает значение .

Одними из первых разработали свой алгоритм метода стохастической аппроксимации в 1951 году Робинсон и Монро. Рекуррентное соотношение Робинсона-Монро, формула 1.1, которую фактически повторяет модель Брауна применительно  к нестационарным рядам. Однако, различие в том, что параметр гамма, демпфирования колебаний, в соотношении Робинсона-Монро является положительным и убывающим, а это значит, что с увеличением количества итераций, то есть количества повторений,  значения функции невязки, той же ошибки, убывают, и значения x(n) стремится к значению x(n-1). 



			(1.2)



Интересными являются способы задания параметра демпфирования колебаний. Наиболее применимыми на практике являются функциональные зависимости данного параметра от количества наблюдений или управляющего воздействия x, формула 1.2, или способы задания данного параметра с нелинейным шагом, например, алгоритм Качмажа для линейной многофакторной модели, формула 1.3, либо с переменным шагом, формулы 1.4 и 1.5.  Практически все алгоритмы предполагают в конечном итоге схождение к оптимальному значению и уменьшение значимости функции невязки. 



					(1.3)



				(1.4)



			(1.5)



В методе стохастической аппроксимации целью является максимальная адаптация модели к эволюционирующему процессу. 

Хотя использование МСА для адаптации моделей является достаточно трудоёмким процессом особенно для нелинейных моделей, однако его применение в большинстве случаев оправдывает затраты, ретроспективные прогнозы с применением МСА получаются точнее.

Теперь рассмотрим МСА на некоторых примерах. В Методах социально-экономического прогнозирования авторов Светунькова С.Г. и Светунькова И.С. рассматриваются различные модели, которые адаптируются с помощью МСА. Однофакторная эконометрическая модель следующего вида:



 					(1.6)



где  коэффициенты модели, которые найдены с помощью МНК и i=0,1,2,…,m-1

m число коэффициентов модели

 фактор, который влияет на показатель 

Процесс адаптации модели проходит следующим образом. Во-первых, из формулы 1.6 выражается коэффициент  через экономический показатель, фактор и остальные коэффициенты и получаем следующее выражение:



					(1.7)



Если в формулу 1.7, вместо расчётного значения , фактическое значение , то новый полученный коэффициент , отличный от расчётного , позволяет модели описывать фактическое наблюдение. В формуле 1.8 представлены фактические коэффициенты.



 					(1.8)



Соответственно чем хуже модель описывает реальное значение, тем сильнее будут отличаться коэффициенты полученные в формулах 1.7 и 1.8. Следовательно, когда разница между фактическим и расчётным коэффициентами увеличивается, коэффициенты модели нуждаются в коррекции. Введение второго индекса t, необходимо потому что, в процессе адаптации расчётные значении коэффициентов меняются во времени. По следующей модификации формулы Роббинсона-Монро будет осуществляться адаптации модели в момент времени t.



			(1.9)



					(1.10)



Где N - последний шаг адаптации коэффициента на предыдущем наблюдении.

В случае аддитивных моделей, исследования показали, что наилучшими в плане адаптации будут являться алгоритмы с постоянным шагом, при этом параметр демпфирования колебаний будет рассчитываться по формуле:



 					(1.11)



Коэффициент k является весовым и характеризует степень адаптации i-го коэффициента по сравнению с остальными, при этом сумма весовых коэффициентов должна быть равно единице. Исследования показали, что значения параметров демпфирования, которые рассчитываются с помощью формулы 1.11 являются оптимальными, то есть адаптация модели происходит за один шаг. Однако является странным момент того, что во всех наблюдениях коэффициенты  модели будут иметь одинаковый вес, так как весьма логично предположить, что влияние свежих данных на будущие значения намного больше, нежели данных оставленных далеко в прошлом.

Если весовой коэффициент одинаков для всех коэффициентов, тогда параметр демпфирования колебаний рассчитывается следующим образом:



 				(1.12)



Адаптация прогнозных моделей происходит в том случае, если во время некоторого наблюдения t реальные значения, вычисленные по предыдущим расчётным значениям коэффициентов, выходят за допустимые границы, то есть выполняется следующее соотношение:



 					(1.13)



где:

 				(1.14)



Дальше действуем по алгоритму представленному выше, то есть выражаем каждый коэффициент линейной однофакторной модели.



 					(1.15)



 					(1.16)



Подставим полученные значения в формулу 1.9 выражения для коэффициентов из формул 1.15 и 1.16.



 	(1.17)



 		(1.18)



В данном случае, используя коэффициенты и , как значения коэффициентов на начальном шаге, в соответствии с уравнением 1.9, получим:



 		(1.19)



 			(1.20)



Выражения в скобках соответствуют уравнению 1.14, получаем упрощённую запись для вычисления адаптированных коэффициентов:



				(1.21)



				(1.22)



Адаптация нелинейных и многофакторных моделей происходит аналогичным, адаптации линейной однофакторной модели, образом. Однако такие модели делятся на 2 вида – это линейные по параметрам и нелинейные по параметрам. В первом случае достаточно линеаризовать модель доступными способами, например логарифмированием. Сложнее обстоит ситуация с моделями нелинейными по параметрам, для адаптации таких моделей, необходимо знать значения параметров демпфирования колебаний, однако получить простую формулу для вычисления данного параметра не получится. Исследования показали, что для такого типа моделей параметры демпфирования колебаний должны быть различны для всех коэффициентов модели.

Алгоритм Роббинсона-Монро с различными его модификациями является основным алгоритмом МСА, однако существуют и другие алгоритмы, которые указывались ранее, такие как, алгоритм Кифера-Вольфовица, который применяется для минимизации среднего значения случайной величины, позволяющий минимизировать функцию регрессии. Такой алгоритм можно применить при построении регрессии, описывающей зависимость затрат фирмы от различных факторов. Суть данного метода в следующем.

Пусть есть случайная величина:



 					(1.23)



задача которая стоит перед нами, найти такое значение параметра α, которое минимизирует среднее значение случайной величины:



				(1.24)



Если функция f(α) известна и дважды дифференциуема, то можно применить известный метод Ньютона:



 			(1.25)



Если функция f(α) неизвестна или есть только предположения о её типе, то предположим, что можно провести эксперимент, в которое наблюдается её случайные значения. Тогда применяется МСА. Пусть  это последовательность положительных конечных интервалов, которые удовлетворяют следующему условию ,  - единичный координатный вектор. Пусть  - k-я оценка векторного параметра и  - k-е наблюдение функции. Если , то для конечно-разностной оценки производной  требуется 2r наблюдений: . Для вектора  и ошибки наблюдения  следующим образом:



		(1.26)



Где i-ая компонента вектора  следующая 

 i-ая компонента вектора  - 



Тогда алгоритм Кифера-Вольфовица имеет следующий вид:



 	(1.27)



 После преобразования алгоритма Кифера-Вольфовица можно использовать его для максимизации среднего значения случайной величины. Тогда есть возможность строить несколько видов прогнозов для проектов: оптимистический, пессимистический, наиболее вероятный. Также существует и широко применяется релаксационный алгоритм Кифера-Вольфовица, который состоит в том,  что итерационный процесс движется в одном координатном направлении в течение одного шага.  

Метод стохастической аппроксимации обладает следующими преимуществами:

Модель позволяет описать любую тенденцию  - для этого достаточно выбрать первоначальную функцию и вывести формулы для пересчёта коэффициентов

Модель позволяет описывать многофакторные зависимости (а не только зависимости от времени, как модификации модели Брауна) 

Модель даёт хорошие прогнозы в среднесрочном аспекте, так как отсеивает шумы, ошибки, и адаптируется только к существенным изменениям тенденций.

Однако, как и любая модель, МСА обладает следующими недостатками:

Нет никакого алгоритма задания величины η – его значение выбирается полностью экспертно на основе оценок

Модель достаточно громоздка, особенно в случае нелинейной по параметрам многофакторной модели.

Нет никакого обоснования того, каким образом должны рассчитываться первоначальные значения коэффициентов.



Разработка динамического интервала отсеивания ошибок, позволит в некотором роде формализовать способ задания величины η, таким образом, есть возможность избавиться от одного недостатка МСА. Так как МСА широко применяется в различных сферах, то данное направление модернизации МСА является актуальным и перспективным.

 1.2. МСА реализация на практике



Построение простой регрессионной модели по всему ряду некорректно, так как связи между факторами постоянно меняются. Причиной этих изменений является эволюция, однако простая адаптация коэффициентов не приводит к желаемому результату, так как нужно адаптироваться к систематическим изменениям. Для таких целей в МСА строится интервал отсеивания ошибок, в котором могут происходить случайные отклонения.

В стандартном МСА предполагается, что исследователь задаёт величину ɳ>0, для получения фильтрующего интервала:



				 (1.28)



Если фактические значения попадают в заданный интервал, то коэффициенты остаются прежними, то есть структурных изменений в ряде данных не произошло. Условие, записанное в неравенстве 1.28, иными словами означает, что модуль разности между фактическими значениями и  предсказанными не превосходит величину ɳ. В случае же, если фактические значения оказываются за пределами фильтрующего интервала, то необходимо определённым образом адаптировать коэффициенты модели. Рассмотрим адаптацию коэффициентов на примере простой парной регрессии. 

Пусть дана парная регрессия:



 				(1.29)



Из уравнения 1.29 мы можем выразить расчётное значение константы:



 				(1.30)



Если в уравнение 1.30 вместо расчётного значения подставить фактическое значение, то мы получим формулу для расчёта фактического значение константы:



 				(1.31)



Фактическое значение константы будет отличаться от расчётного на следующую величину:



 	(1.32)



Проведя аналогичные рассуждения для угла наклона, получаем следующее соотношение между фактическим и расчётным углами наклона:



 				(1.33)



Теперь необходимо адаптировать старые коэффициенты с учётом изменений. 



 				(1.34)



 				(1.35)



В формуле 1.34 записана адаптация для константы, в формуле 1.35 – для угла наклона, где  – это вес i-го коэффициента регрессии, а  - коэффициент демпфирования колебаний. 

Стандартный метод задания весов – это когда все коэффициенты адаптируются с одинаковой скоростью, однако возможны и другие способы, когда коэффициенты регрессии адаптируются с различной скоростью. Основным условием для весов является следующее:



					(1.36)



Возможны следующие ситуации:

 - веса делятся поровну

 - адаптируется только константа

 - адаптируется только угол наклона

 - адаптация коэффициентов происходит  противоположные стороны.

Параметр  определяет скорость адаптации, в качестве примера взята курсовая стоимость акций Норильского Никеля за период с 01.04.2009 по 01.04.2013 по месячным данным по ценам закрытия. Всего 49 наблюдений. При построении МНК модели будет использована зависимость курсовой стоимости акций Норильского Никеля от стоимости никеля за аналогичный период:

 - модель всегда адаптируется с одинаковой скоростью

 –модель будет всегда подтягиваться к крайней границе интервала. Такой способ задания параметра  подходит для рядов с незначительными изменениями.

  - модель будет подтягиваться так, что бы фактические значения оказались внутри интервала

 – модель подтягивается к точке противоположной границы

 - модель подтягивается к точке верхней границы

 – модель подтягивается к точке нижней границы



После применения МСА к выбранному ряду данных получили следующую картину (рисунок 1):





Рисунок 1 МСА для ряда данных



При оценке качества модели использовался параметр sMAPE, (чем он меньше, тем лучше), который рассчитывается по следующей формуле:



 				(1.37)



sMAPE в данному случае оказался равным 5,54%. При этом по графику можно увидеть, что модель оказалась достаточно чувствительной к шумам, что является проблемой, так как шумы как раз должны отсеиваться, а не усиливаться. Но в целом фактические значения находятся в пределах интервалов, и МСА оказался лучше, чем обычный МНК, для которого sMAPE=7,29%. При этом параметр ɳ никак не регулировал ширину интервала, так как был равен постоянной величине, средней абсолютной ошибке, которая считается по формуле:



 				(1.38)



Таким образом, в МСА адаптация происходит в 2 этапа, во-первых, отсев шумов за счёт параметра ɳ, во-вторых, адаптация модели за счёт параметра демпфирования колебаний .

Однако в методе стохастической аппроксимации есть 2 существенные проблемы:

Задание параметра ɳ

Задание стартовых значений

В качестве стартовых значений коэффициентов, можно взять значения коэффициентов, которые получены при построении обычной МНК модели и уже исходя из них, рассчитывать параметр ɳ, к примеру, следующим способом:

Из построенной МНК модели, рассчитать ошибки

Взять наибольшую по модулю ошибку

На основе её рассчитать параметр 

При этом регулируя величину β можно задавать ширину границ. 



















Глава 2. МСА с динамическим фильтром отсеивания ошибок

 2.1. Методика построения МСА с динамическим фильтром



Как мы видели в прошлой главе, реализация МСА на практике затруднена, так как метод обладает рядом минусов. В данной главе мы займёмся устранением некоторых из этих минусов и, как следствие, получим более формализованный и преобразованный метод стохастической аппроксимации. 

Первым и достаточно серьёзным минусом, на мой взгляд, является то, что всем наблюдениям придаётся одинаковый вес на всем временном интервале. Так как мы имеем дело в основном с временными рядами, то наиболее ценными для нас являются наблюдения, которые максимально приближены к  настоящему моменту, конечно в зависимости от того, данные с какой периодичностью мы используем час, день, месяц, год. В таком случае логичнее было бы придавать наибольший вес данным, которые находятся в непосредственной близости от настоящего момента, так как, например, при прогнозировании инфляции на 2014 и 2015 года, мы вряд ли будем использовать данные об инфляции в период до 2000 года, а наиболее ценными для нас окажутся показатели инфляции за 3-4 предыдущих года. Задача сводится к формализованному правилу выбора весов для наблюдений.

В целях экономии времени при построении МСА и целесообразности проведения громоздких вычислений, веса будут распределяться между группами наблюдений, которые входят в один интересующий нас интервал.

Временной интервал разбивается на 4 группы наблюдений, почему именно на 4 группы поговорим чуть позже. При этом наиболее отстоящий от настоящего момента времени интервал корректируется на оставшееся количество групп. Оставшееся количество наблюдений разбивается на 3 части и так же корректируется на оставшееся количество групп. Аналогичным способом формируется 3-я группа наблюдений или подвыборка. Самая приближенная к настоящему моменту подвыборка равно общему количеству наблюдений за вычетом количества наблюдений во всех остальных группах. 

Формализуем вышеизложенные рассуждения. Количество наблюдений в первой подвыборке определяется из следующей формулы:



 					(2.1)



где   - количество наблюдений в первой подвыборке, n – общее количество наблюдений, 3 – оставшееся количество групп наблюдений. При этом округление количества наблюдений идёт вниз, то есть даже получив 12,9 наблюдений для группы по какой либо из формул, количество наблюдений в данной группе будет равно 12.



					(2.2)



					(2.3)



 				(2.4)



	Таким образом, количество наблюдений входящих в подвыборки будет варьироваться от меньшего к большему, причём в группе наблюдений наиболее приближенных к настоящему моменту, то есть в  - будет наибольшее количество наблюдений.

Пример 1.

Пусть в выборке есть 50 наблюдений и нам необходимо разбить данные наблюдения по 4 группам. Тогда в соответствии с формулами 39-40, получаем следующее количество наблюдений в каждой группе:

; округляя вниз, получим 9 наблюдений для первой подвыборки.

 соответственно во второй подвыборке будет 11 наблюдений.

 в третьей подвыборке 14 наблюдений.

; в подвыборке, которая наиболее приближена к настоящему моменту времени будет содержаться 16 наблюдений.

После того, как мы определили количество наблюдений в каждой подвыборке, мы можем присвоить им вес в зависимости от количества наблюдений. Веса для каждой подвыборки будут формироваться по следующему правилу:



 					(2.5)



Где  – количество наблюдений в каждой подвыборке и n – общее количество наблюдений, а  - вес каждого наблюдения в соответствующей подвыборке. 

Пример 2.

Исходя из разделения группы наблюдений на подвыборки (смотри пример 1) и, используя формулу 43 получим веса для коэффициентов в каждой подвыборке.

 - вес коэффициентов модели в первой подвыборке.

=0,22 – вес коэффициентов во второй подвыборке.

 - вес коэффициентов  третьей подвыборке.

 - вес коэффициентов в чётвёртой подвыборке.

Фактически условие того, что сумма весов равна 1 сохраняется и для такой модификации МСА, только если в обычном МСА сумма весов коэффициентов по горизонтали была равна 1, то в данном случае она равна 1 по вертикали за счёт чего и достигается динамика фильтрующего ошибки интервала.

Таким образом, в отличие от первоначального способа задания весов в МСА, когда вес присваивался каждому коэффициенту в отдельности и оставался неизменным на всём интервале как фактическом, так и прогнозируемом, в описанном выше способе, вес наблюдения, соответственно и коэффициентов модели является величиной динамической и увеличивается с приближением к настоящему моменту времени. Однако вес остаётся неизменным для самих коэффициентов, то есть каждый коэффициент адаптируется с одинаковой скоростью для каждого наблюдения внутри группы,  и с разной – для наблюдений в разных группах.

Последний параметр, способ задания которого в обычном МСА был условно формализован, это параметр ɳ, который задаёт ширину интервала. В обычном МСА условная формализация заключалась в том, что способ задания параметра β не был точно задан, а значение подбиралось с помощью МНК. Теперь же параметр β можно привязать к значению веса группы наблюдений обратным соотношением, то есть:



 					(2.6)



Где  параметр регулирующий ширину фильтрующего интервала для каждой группы наблюдений из выборки.

Теперь можно записать формулу для параметра, задающего ширину интервала, то есть ɳ:



				 (2.7)

Где MAE  - средняя абсолютная ошибка, которая является постоянной величиной. Именно за счёт параметра β фильтрующий интервал становится динамическим, а за счёт того, что он привязывается к количеству наблюдений, мы получаем формализацию метода.

Вместо средней абсолютной ошибки, формула для вычисления которой приводилась в предыдущей главе, можно использовать максимальную по модулю ошибку, так же можно рассчитывать среднюю абсолютную ошибку, высчитанную для каждой подвыборки отдельно, однако процесс расчёта параметра ширины интервала в данном случае затягивается и усложняется, наша же цель а данному случае формализовать весь процесс при минимальном или равносильном усложнении МСА.

Пример 3.

Пусть средняя абсолютная ошибка равна 60, тогда на основе примеров 1, 2 и формул 2.6 и 2.7 можно вычислить значения параметра фильтрующего интервала для каждой подвыборки.



 

 

 

 



Выше представлены значения ширины интервалов для соответствующих подвыборок, как видно ширина интервала меняется в зависимости от подвыборки, чем ближе к настоящему моменту времени, тем уже становится интервал отсеивания ошибок.

При построении динамического фильтрующего интервала отсеивания ошибок можно использовать следующий алгоритм:

Определить количество наблюдений в каждой подвыборке по следующей общей формуле:



 				(2.8)



где  - количество наблюдений в i-ой подвыборке, n – количество наблюдений, m – количество оставшихся подвыборок (или номера подвыборок в обратном порядке),  - количество наблюдений в предыдущих подвыборках.

Взвесить коэффициенты в соответствии с формулой 2.5.

Рассчитать значения параметра β для каждой подвыборки по формуле 2.6.

Рассчитать значения параметра ɳ по формуле 2.7.

 Реализацию модифицированного МСА мы рассмотрим в следующем параграфе. 



2.2. Построение динамического фильтра отсеивания ошибок



Рассмотрим реализацию модифицированного МСА на различных данных с помощью алгоритма описанного в предыдущем параграфе. О том, как прогнозировать с помощью данного метода поговорим после примеров с применением МСА с динамическим интервалом. 

Первый ряд данных, по которому будет построен динамический фильтрующий интервал – это курсовая стоимость акций Норильского Никеля в период с 01.04.2009 по 01.04.2013 с интервалом в месяц и всего 49 наблюдений. Норильский Никель является крупнейшим в мире производителем никеля и палладия и одним из крупнейших в мире производителем меди и платины. Основными видами деятельности компании являются поиск, разведка, добыча, обогащение и переработка полезных ископаемых, а также производство и реализация цветных металлов.

Стартовые значения будут задаваться с помощью построения МНК регрессии, которая отражает зависимость  между курсовой стоимость акций и стоимостью никеля за аналогичный период. Мы можем применять парную регрессию для задания стартовых значений, так как на начальном этапе нам необходимо максимально упростить метод, главное чтобы регрессия оказалась в целом значима, что будет говорить и о значимости коэффициента, а объясняющая способность модели высокая.

Таким образом, стартовые значения будут следующими:



Таблица 1 

Стартовые значения для Норильскго Никеля



Теперь в соответствии с алгоритмом, изложенным в предыдущем параграфе, рассчитаем значения основных параметров.

Выборку, как и в примерах предыдущего параграфа мы будем разбивать на 4 части, соответственно опираясь на формулу 46 и на то, что количество наблюдений равно 49, получи следующее



 - следовательно, количество наблюдений в первой подвыборке равно 9

 - количество наблюдений во второй подвыборке 11

 - количество наблюдений в третьей подвыборке 13

 – количество наблюдений в четвёртой подвыборке

Веса коэффициентов распределяются следующим образом:

 

 

 

 

Значения параметра β будут следующими

 

 

 

 

Параметр, задающий ширину интервала, равен следующим значениям, которые рассчитаны в соответствии с формулой 45, при этом MAE=548,47

Способ же задания фактического значения и критерии адаптации коэффициентов остались прежними.

Рассмотрим на графиках разницу между МСА и МСА с динамическим фильтром отсеивания ошибок: 





Рисунок 2 МСА



sMAPE=10.76%





Рисунок 3 МСА с динамическим фильтром



sMAPE=7,79%

Вертикальными линиями на графике, изображённом на рисунке 3 обозначена граница подвыборок.. Показатели качества оценивания sMAPE и величину RSS сведём в таблицу:



Таблица 2

Сравнение МСА и МСА с динамическим фильтром для Норильского Никеля



Как видно для МСА c динамическим фильтром аппроксимация лучше, чем для обычного МСА, а также значение RSS меньше. Из анализа графиков можно сказать, что шумоподавление у МСА с динамическим фильтром лучше. 

Теперь рассмотрим МСА и МСА с ДФ при разбиении на 3 подвыборки, при этом будем использовать регрессию описывающую зависимость курсовой стоимости акций ЛУКОЙЛа от стоимости бензина. Данные с 1.04.2009 до 1.04.2013 с интервалом месяц, всего 49 наблюдений. Стартовые значения следующие:



Таблица 3 

Стартовые значения для Лукойла



Используемый показатель MAE для обоих случаев равен 84,92.





Рисунок 4 МСА для ЛУКОЙЛа



sMAPE=4,85%



При разбиении на 3 подвыборки получим следующие результаты:

 

 

 



  

 

 

 

 

 





Рисунок 5 МСА с динамическим фильтром для ЛУКОЙЛа



sMAPE=3,39%



Таблица 4 

Сравнение МСА и МСА с ДФ для Лукойла



Как видно из таблицы 4 МСА с динамическим интервалом вновь показывает лучшую аппроксимацию с меньшей RSS.

Теперь рассмотрим МСА с динамическим фильтром отсеивания ошибок при разбиении выборки на 5 подвыборок. Рассматривать будем на примере МНК регрессии описывающей зависимость курсовой стоимости акций ОАО «НОВАТЭК», компания которая занимается геологоразведкой  месторождений углеводородов, добычей, переработкой и реализацией газа и жидких углеводородов от стоимости мазута за период и интервалы аналогичные предыдущим рассматриваемым рядам.

Стартовые значения следующие:



Таблица 5 

Стартовые значения для НОВАТЭКа



При разбиении выборки на 5 подвыборок, получим следующие значения основных параметров, необходимых для задания динамического фильтра отсеивания ошибок:

 

 

 

 

 



  

 

 

 

 



 

 

 

 

 





Рисунок 6 МСА для НОВАТЭК



sMAPE=10,25%





Рисунок 7 МСА с динамическим фильтром для НОВАТЭК

sMAPE=7,51%



Таблица 6 

Сравнение МСА и МСА с ДФ для НОВАТЭК



Как и в предыдущих случаях МСА с динамическим фильтром показывает результаты лучше, чем обычный МСА по основным критериям сравнения sMAPE и RSS.



2.3. Прогнозирование с помощью МСА с динамическим фильтром



При прогнозировании с помощью МСА с динамическим фильтром главным условием является то, что нужно точно определить на какой период времени мы хотим построить прогноз. Данное условие является основным, так как нам необходимо заранее задать веса и интервалы. То есть если мы хотим построить прогноз на 6 периодов вперёд, а имеем фактические значения за 43 наблюдения, то в МСА с динамическим фильтром необходимо задавать параметры на все 49 наблюдений. Конечно, такой способ построения прогноза является достаточно громоздким, однако разница в результатах адаптации коэффициентов модели с помощью МСА и МСА с динамическим фильтром наглядно покажет, что данная громоздкость себя оправдывает. В целях оптимизации данного процесса, для построения прогноза будем использовать временные ряды, по которым строились МСА и МСА с динамическим интервалом в предыдущем параграфе. Соответственно стартовые значения, разбиение на подвыборки, а также основные параметры останутся прежними. Прогноз в каждом временной ряде будет осуществляться на 3 периода вперёд, то есть при взятых интервалах, прогноз осуществляется на 3 месяца, так как МСА производит адаптацию коэффициентов, то смысла делать долгосрочные прогнозы, нет. Значения коэффициентов для модели, описывающей стоимость акций Норильского никеля следующие:



Таблица 7 

Стартовые значения для ретроспективного прогноза по Норильскому Никелю



При построении ретроспективного прогноза получаем следующую картину, рисунок 8 до получения фактических значений, рисунок 9 – после.





Рисунок 8 Ретроспективный прогноз по МСА для Норильского Никеля





Рисунок 9 Ретроспективный прогноз с фактом для Норильского Никеля



Таблица 8 

МСА для Норильского Никеля



Как видно из графиков представленных на рисунках  8 и 9 практически все фактические значения прошли по нижней границе интервала, при этом аппроксимация стала лучше. Теперь рассмотрим, каким будет ретроспективный прогноз для аналогичной зависимости, но уже с использованием МСА с динамическим фильтром. Стартовые значении коэффициентов указаны в таблице 7.





Рисунок 10 Ретроспективный прогноз для Норильского Никеля по МСА с ДФ





Рисунок 11 Ретроспективный прогноз с фактом по МСА с ДФ для Норильского Никеля





Таблица 9

МСА с ДФ для Норильского Никеля



По полученным в таблице  9 результатом, можно сказать, что для данного временного ряда, адаптация коэффициентов с помощью МСА с динамическим фильтром оказалась лучше, чем при обычном МСА, так как аппроксимация как до получения фактических значений так и после для МСА с ДФ оказалась лучше. 

Для наглядности рассмотрим на графике ретроспективные прогнозы по обоим методам до получения фактических значений и после. Как видно по графикам, представленным на рисунках 12 и 13 МСА с динамическим фильтром даёт ретроспективный прогноз лучше, чем обычный МСА.





Рисунок 12 Ретроспективный прогноз по МСА и МСА с ДФ до получения факта





Рисунок 13 Ретроспективный прогноз по МСА и МСА с ДФ после получения фактических значений



Аналогичные прогнозы были построены ещё по 50 моделям, с результатами адаптации можно ознакомиться в приложении 1. Если закрашена только первая ячейка по модели, то сказать определённо, какой из методов адаптации лучше – нельзя, если закрашены 2 ячейки, то МСА с динамическим фильтром оказался лучше, таким образом, доля моделей, в которых МСА с динамическим фильтром оказался лучше составляет 69%. 



































Заключение



Современные социально-экономические реалии показывают, что без построения точных прогнозов не обходится практически ни один процесс принятия сложных, определяющих решений. Метод стохастической аппроксимации направлен то, чтобы путём адаптации коэффициентов моделей, описывающих различные явления и процессы, принятые решения были эффективными. Однако при всех преимуществах МСА, он обладает рядом минусов, в частности слабой формализацией при задании ряда параметров. Одним из наиболее важных параметров в МСА, является ширина фильтрующего ошибки интервала, который и позволяет нам определённее сказать, куда попадёт исследуемая величина. Именно формализации способа задания фильтра ошибок и посвящена моя выпускная квалификационная работа.

Основное задачей, было выявление, с помощью каких дополнительных параметров формализация будет успешной и приведёт к ожидаемому результату – модернизация МСА и повышение точности прогноза. Дополнительными параметрами стали следующие:

Подвыборки и изменяющееся количество наблюдений в них

Динамический вес для каждой подвыборки, который был привязан к количеству наблюдений

Благодаря привязке ширины фильтра к количеству наблюдений во всём ряде данных, а также в каждой подвыборке,  количеству подвыборок и весу, удалось формализовать способ задания фильтра ошибок, а также сделать его динамическим. Преимущество динамического фильтра заключается в сужении интервалов отсеивания ошибок при приближении к настоящему моменту или же при построении прогноза, что в свою очередь в большинстве случаев, в 69%, увеличивает точность прогнозов. 

Таким образом, основная цель моей выпускной квалификационной работы – модернизация и улучшение МСА достигнута, а поставленные задачи решены. В связи с чем считаю, что динамический фильтр в МСА полностью применим на практике. Также возможно продолжить исследования по данному вопросу в следующих направлениях:

Динамика аппроксимации при изменении количества подвыборок.

Основным предположением такого развития тематики ВКР является то, что при увеличении количества подвыборок увеличивается степень аппроксимакции, а также точность прогноза. Однако, хоть и разбиение на большое количество подвыборок, то есть практически равное количеству наблюдений, в гипотезе может дать большую точность прогноза, предельная полезность от добавления каждой последующей подвыборки может уменьшиться при значительном увеличении трудоёмкости.

Обоснование методики выбора количества подвыброк.

Количество подвыборок на данный момент является величиной задающейся произвольно, поэтому необходимо провести исследования, с помощью которых можно будет установить зависимость между количеством подвыброк и точностью прогноза, а также на какое количество подвыборок оптимальнее всего разбивать ряд данных, состоящий из определённого количества наблюдений

Горизонтальный и вертикальный динамические фильтры.

Как было сказано в ВКР, для построения прогноза нам необходимо заранее определиться с периодом прогнозирования, что позволяло нам получить вертикальный динамический фильтр, но в целом весь он был статичен в пределах выбранного количества наблюдений и периода прогноза. В целях адаптации МСА с динамическим фильтром отсеивания ошибок к учёту поступающей информации, возможна автоматизация процесса расчёта ширины динамического фильтра при его горизонтальном движении.





Список использованной литературы



Вазян М. Стохастическая аппроксимация – М.: Изд-во МИР, 1972. – 292 с.

Граничин О.Н. Введение в методы стохастической оптимизации и оценивания: Учеб. пособие  – СПб.: Изд-во СПбГУ, 2003. – 131 с. 

Ермольев Ю.М. методы стохастического программирования – М.: Наука, 1976. – 239 с. 

Ильин В.А., Позняк Э.Г. Аналитическая геометрия:  Учебник для вузов – 5-е изд. – М.: Физматлит, 1999 –223 с

Катковник В.Я. Линейные оценки и стохастические задачи оптимизации – М.: Наука, 1976. – 487 с.

Левицкий  Е. М. Адаптивные эконометрические модели -  Акад. Наук СССР. Сиб. отд-ние. Ин-т экономики и орг. пром. пр-ва. – Новосибирск: Наука. Сиб. отд-ние, 1981. – 184 с.

Левицкий Е. М. Адаптация в моделировании экономических систем Акад. Наук СССР. Сиб. отд-ние Ин-т экономики и орг. пром. пр-ва. – Новосибириск: Наука. Сиб. отд-ние, 1977. – 208 с.

Лукашин Ю.П. Адаптивные методы краткосрочного прогнозирования временных рядов: Учеб. пособие – М.: Финансы и Статистика, 2003. 

Льюис К.Д. Методы прогнозирования экономических показателей – М.: Финансы и статистика, 1986

 Назин А.В., Позняк А.С. Адаптивный выбор вариантов: реккуретные алгоритмы – М.: Наука, 1986. – 287 с.

 Невельсон М.Б., Хасьминский Р.З. Стохастическая аппроксимация   и реккуретное оценивание – М.: Наука, 1972. – 304 с

 Поляк Б.Т. Введение в оптимизацию – М.: Наука, 1983. – 384 с.

 Растригин Л. А. Адаптация сложных систем – Рига: Зинатие, 1981 – 386 с. 

 Светуньков С.Г., Светуньков И.С. Методы социально-экономического прогнозирования: Учебник для вузов. Том II. – СПб.: Изд-во СПбГУЭФ, 2010. – 105 с.

 Светуньков С.Г. Количественные методы прогнозирования эволюционных составляющих экономической динамики – Ульяновск: Изд-во УлГУ, 1999.

 Светуньков С.Г., Параметры демпфирования колебаний при адаптивном подходе к задаче идентификации динамических систем // Моделирование и разработка технических средств для АСУ ТП. – Ташкент; ТашПИ, 1987.

 Срагович В.Г. Адаптивное управление – М.: Наука, 1981 – 384 с.

 Урясьев С.П. Адаптивные алгоритмы стохастической оптимизации и теории игр – М.: Наука, 1990. – 182 с. 

 Фомин В.Н. Реккуретное оценивание и адаптивная фильтрация – М.: Наука, 1984. – 288 с.   

 Цыпкин Я.З. Адаптация и обучения в автоматических системах – М.: Наука, 1968. – 400 с.

 Цыпкин Я.З. Основы теории обучающих систем – М.: Наука, 1970. – 252 с.

 Шильман С.В. адаптивная фильтрация временных рядов – Н. Новгород: Изд-ва Н.-Новг, 1995. – 180 с.

 M. Benaim. Dynamics of stochastic approximation algorithms. Sprtinger-Verlag, Berlin and New York, 1-69p., 1999.

 R. Buche and H.J. Kushner. Rate of convergence for constrained stochastic approximation algorithms. SIAM. J. Control Optim., 1041, 2001.

 H.-F. Chen. Stochastic Approximation and Its Applications. Kluwer Academic, Boston, 2002

 B. Delyon and A. Juditsky. Stochastic optimization with averaging of trajectories. Stochastics Stochastic Rep., 118, 1992

 P. Dupuis and H.J. Kushner. Stochastic approximation via large deviations: Asymptotic properties. SIAM J. Control Optim., 696, 1985

 E.G. Gladyshev. On stochastic approximation. Theory Probab. Appl., 278, 1965

 Harold J. Kushner, G. George Yin. Stochastic Approximation and Recursive Algorithms and Application. Springer. 497, 2003

 A. Juditsky. A stochastic estimation algorithm with observation averaging. IEEE Trans. Automatic Control, 798, 1993

 Финам URL: 







































Приложение 



